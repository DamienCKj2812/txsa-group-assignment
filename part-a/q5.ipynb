{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d3b4e5f",
   "metadata": {},
   "source": [
    "# Q5. Alternative Approach Implementation (Individual Component)\n",
    "\n",
    "This notebook demonstrates an alternative tokenization technique using **TextBlob** and compares it with the group's approach (NLTK, Split, and Regex)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc694cd6",
   "metadata": {},
   "source": [
    "---\n",
    "- ### *Chong Kah Jun (TP067165)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3b4c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import nltk\n",
    "\n",
    "# Ensure necessary NLTK data is available (TextBlob uses NLTK under the hood)\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load the data\n",
    "file_path = '../assets/dataset-a/Data_1.txt'\n",
    "with open(file_path, 'r') as file:\n",
    "    text = file.read().strip()\n",
    "\n",
    "print(\"Original Text:\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4f5g6h",
   "metadata": {},
   "source": [
    "**Implement tokenization using an alternative approach (TextBlob)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5b6c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TextBlob object\n",
    "blob = TextBlob(text)\n",
    "\n",
    "# Extract words using the .words property\n",
    "tokens_textblob = blob.words\n",
    "\n",
    "print(\"Tokenization using TextBlob:\")\n",
    "print(list(tokens_textblob)[:20], \"...\")\n",
    "print(f\"\\nTotal tokens found: {len(tokens_textblob)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6f7g8h",
   "metadata": {},
   "source": [
    "**Compare and contrast the alternative approach with the groupâ€™s approach**\n",
    "\n",
    "| Feature | Group Approach (NLTK `word_tokenize`) | Alternative Approach (`TextBlob.words`) |\n",
    "| :--- | :--- | :--- |\n",
    "| Data Type | Returns a standard Python `list` of strings. | Returns a `WordList` object (a subclass of list). |\n",
    "| Punctuation | Retains punctuation as separate tokens. | Automatically filters out punctuation by default. |\n",
    "| API Style | Functional/Procedural (`word_tokenize(text)`). | Object-Oriented (`blob.words`). |\n",
    "| Underlying Engine | Uses the Punkt tokenizer. | Uses NLTK's tokenizer but wraps it for ease of use. |\n",
    "\n",
    "Contrast:\n",
    "While NLTK's `word_tokenize` provides a list of all characters including periods and commas, `TextBlob` specifically targets \"words\" and omits standard punctuation marks immediately. This makes `TextBlob`'s output cleaner for word-frequency tasks but less useful for syntactic analysis where punctuation markers are needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6g7h8i9j",
   "metadata": {},
   "source": [
    "**Explain why the alternative approach is better, worse, or just different**\n",
    "\n",
    "Evaluation:\n",
    "\n",
    "Why it is Different:\n",
    "The `TextBlob` approach is \"just different\" in its design philosophy. It is built for ease of use and rapid prototyping. Unlike the group approach which requires manual filtering of punctuation (as shown in Q1.c), `TextBlob.words` performs a basic level of filtering during the tokenization phase itself.\n",
    "\n",
    "Pros (Better for specific tasks):\n",
    "1. Ease of Use: The API is more intuitive for developers. Once a `TextBlob` object is created, multiple attributes (sentences, words, sentiment, tags) are accessible without calling different functions.\n",
    "2. Built-in Methods: The `WordList` returned by `TextBlob` has convenient methods like `.lemmatize()` and `.singularize()`, which can be called directly on the list, reducing the need for loops.\n",
    "\n",
    "Cons (Worse for specific tasks):\n",
    "1. Transparency: It abstracts away the tokenization process. In complex NLP pipelines, a researcher might want to know exactly how a period is handled. `TextBlob` makes assumptions that might not always be desired.\n",
    "2. Punctuation Loss: If the task requires knowing the end of a sentence through punctuation or identifying symbols (like in code analysis), `TextBlob.words` is worse because it discards them by default."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
